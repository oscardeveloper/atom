(function() {
  var ArgumentListItemRegex, Doc, ReturnsRegex, SpecialHeadingDepth, SpecialHeadings, VisibilityRegex, generateBlockquote, generateCode, generateDescription, generateHeading, generateList, generateParagraph, getLinkMatch, isArgumentListItem, isAtArgumentList, isReturnValue, marked, multiplyString, parse, parseArgumentList, parseArgumentsSection, parseEventsSection, parseExamplesSection, parseListItem, parseReturnValues, parseSummaryAndDescription, parseTitledArgumentsSection, stopOnSectionBoundaries, _, _ref;

  _ = require('underscore');

  marked = require('marked');

  Doc = require('./doc');

  _ref = require('./utils'), getLinkMatch = _ref.getLinkMatch, multiplyString = _ref.multiplyString;

  SpecialHeadingDepth = 2;

  SpecialHeadings = '^Arguments|Events|Examples';

  VisibilityRegex = '^\\s*([a-zA-Z]+):\\s*';

  ReturnsRegex = "(" + VisibilityRegex + ")?\\s*Returns";

  ArgumentListItemRegex = '^\\s*`([\\w\\.-]+)`(\\s*[:-])?(\\s*\\(optional\\))?\\s*';

  /*
  Section: Parsing
  
  Translating things from markdown into our json format.
  */


  parse = function(docString) {
    var args, doc, events, examples, extraDescription, firstToken, lexer, returnValues, titledArgs, tokens;
    lexer = new marked.Lexer();
    tokens = lexer.lex(docString);
    firstToken = _.first(tokens);
    if (!(firstToken && firstToken.type === 'paragraph')) {
      throw new Error('Doc string must start with a paragraph!');
    }
    doc = new Doc(docString);
    _.extend(doc, parseSummaryAndDescription(tokens));
    while (tokens.length) {
      if (titledArgs = parseTitledArgumentsSection(tokens)) {
        if (doc.titledArguments == null) {
          doc.titledArguments = [];
        }
        doc.titledArguments.push(titledArgs);
      } else if (args = parseArgumentsSection(tokens)) {
        doc["arguments"] = args;
      } else if (events = parseEventsSection(tokens)) {
        doc.events = events;
      } else if (examples = parseExamplesSection(tokens)) {
        doc.examples = examples;
      } else if (returnValues = parseReturnValues(tokens, true)) {
        doc.setReturnValues(returnValues);
      } else {
        extraDescription = generateDescription(tokens, stopOnSectionBoundaries);
        doc.description += "\n\n" + extraDescription;
      }
    }
    return doc;
  };

  parseSummaryAndDescription = function(tokens, tokenCallback) {
    var description, rawSummary, rawVisibility, returnValues, summary, visibility, visibilityMatch;
    if (tokenCallback == null) {
      tokenCallback = stopOnSectionBoundaries;
    }
    summary = '';
    description = '';
    visibility = 'Private';
    rawVisibility = null;
    rawSummary = tokens[0].text;
    if (rawSummary) {
      if (visibilityMatch = new RegExp(VisibilityRegex).exec(rawSummary)) {
        visibility = visibilityMatch[1];
        rawVisibility = visibilityMatch[0];
        rawSummary = rawSummary.replace(rawVisibility, '');
      }
    }
    if (isReturnValue(rawSummary)) {
      returnValues = parseReturnValues(tokens, false);
      return {
        summary: summary,
        description: description,
        visibility: visibility,
        returnValues: returnValues
      };
    } else {
      summary = rawSummary;
      description = generateDescription(tokens, tokenCallback);
      if (rawVisibility != null) {
        description = description.replace(rawVisibility, '');
      }
      return {
        description: description,
        summary: summary,
        visibility: visibility
      };
    }
  };

  parseArgumentsSection = function(tokens) {
    var args, firstToken;
    firstToken = _.first(tokens);
    if (firstToken && firstToken.type === 'heading') {
      if (!(firstToken.text === 'Arguments' && firstToken.depth === SpecialHeadingDepth)) {
        return;
      }
    } else if (firstToken && firstToken.type === 'list_start') {
      if (!isAtArgumentList(tokens)) {
        return;
      }
    } else {
      return;
    }
    args = null;
    if (firstToken.type === 'list_start') {
      args = parseArgumentList(tokens);
    } else {
      tokens.shift();
      generateDescription(tokens, stopOnSectionBoundaries);
      args = parseArgumentList(tokens);
    }
    return args;
  };

  parseTitledArgumentsSection = function(tokens) {
    var firstToken;
    firstToken = _.first(tokens);
    if (!(firstToken && firstToken.type === 'heading')) {
      return;
    }
    if (!(firstToken.text.indexOf('Arguments:') === 0 && firstToken.depth === SpecialHeadingDepth)) {
      return;
    }
    return {
      title: tokens.shift().text.replace('Arguments:', '').trim(),
      description: generateDescription(tokens, stopOnSectionBoundaries),
      "arguments": parseArgumentList(tokens)
    };
  };

  parseEventsSection = function(tokens) {
    var args, description, eventHeadingDepth, events, firstToken, name, stopTokenCallback, summary, visibility, _ref1;
    firstToken = _.first(tokens);
    if (!(firstToken && firstToken.type === 'heading' && firstToken.text === 'Events' && firstToken.depth === SpecialHeadingDepth)) {
      return;
    }
    eventHeadingDepth = SpecialHeadingDepth + 1;
    stopTokenCallback = function(token, tokens) {
      if (token.type === 'heading' && token.depth === eventHeadingDepth) {
        return false;
      }
      return stopOnSectionBoundaries(token, tokens);
    };
    events = [];
    tokens.shift();
    while (tokens.length) {
      generateDescription(tokens, stopTokenCallback);
      firstToken = _.first(tokens);
      if ((firstToken != null ? firstToken.type : void 0) === 'heading' && firstToken.depth === eventHeadingDepth) {
        tokens.shift();
        _ref1 = parseSummaryAndDescription(tokens, stopTokenCallback), summary = _ref1.summary, description = _ref1.description, visibility = _ref1.visibility;
        name = firstToken.text;
        args = parseArgumentList(tokens);
        if (args.length === 0) {
          args = null;
        }
        events.push({
          name: name,
          summary: summary,
          description: description,
          visibility: visibility,
          "arguments": args
        });
      } else {
        break;
      }
    }
    if (events.length) {
      return events;
    }
  };

  parseExamplesSection = function(tokens) {
    var description, example, examples, firstToken;
    firstToken = _.first(tokens);
    if (!(firstToken && firstToken.type === 'heading' && firstToken.text === 'Examples' && firstToken.depth === SpecialHeadingDepth)) {
      return;
    }
    examples = [];
    tokens.shift();
    while (tokens.length) {
      description = generateDescription(tokens, function(token, tokens) {
        if (token.type === 'code') {
          return false;
        }
        return stopOnSectionBoundaries(token, tokens);
      });
      firstToken = _.first(tokens);
      if (firstToken.type === 'code') {
        example = {
          description: description,
          lang: firstToken.lang,
          code: firstToken.text,
          raw: generateCode(tokens)
        };
        examples.push(example);
      } else {
        break;
      }
    }
    if (examples.length) {
      return examples;
    }
  };

  parseReturnValues = function(tokens, consumeTokensAfterReturn) {
    var firstToken, nextIndex, normalizedString, returnString, returnValues, returnsMatches, token, _ref1;
    if (consumeTokensAfterReturn == null) {
      consumeTokensAfterReturn = false;
    }
    firstToken = _.first(tokens);
    if (!(firstToken && ((_ref1 = firstToken.type) === 'paragraph' || _ref1 === 'text') && isReturnValue(firstToken.text))) {
      return;
    }
    returnsMatches = new RegExp(ReturnsRegex).exec(firstToken.text);
    if (consumeTokensAfterReturn) {
      normalizedString = generateDescription(tokens, function() {
        return true;
      }).replace(returnsMatches[1], '');
    } else {
      token = tokens.shift();
      normalizedString = token.text.replace(returnsMatches[1], '').replace(/\s{2,}/g, ' ');
    }
    returnValues = null;
    while (normalizedString) {
      nextIndex = normalizedString.indexOf('Returns', 1);
      returnString = normalizedString;
      if (nextIndex > -1) {
        returnString = normalizedString.substring(0, nextIndex);
        normalizedString = normalizedString.substring(nextIndex, normalizedString.length);
      } else {
        normalizedString = null;
      }
      if (returnValues == null) {
        returnValues = [];
      }
      returnValues.push({
        type: getLinkMatch(returnString),
        description: returnString.trim()
      });
    }
    return returnValues;
  };

  parseArgumentList = function(tokens) {
    var args, argument, argumentStack, argumentsList, argumentsListStack, depth, parseAsArgumentList, token;
    depth = 0;
    args = [];
    argumentsList = null;
    argumentsListStack = [];
    argument = null;
    argumentStack = [];
    while (tokens.length && (tokens[0].type === 'list_start' || depth)) {
      token = tokens[0];
      switch (token.type) {
        case 'list_start':
          parseAsArgumentList = isAtArgumentList(tokens);
          if (parseAsArgumentList) {
            depth++;
            if (argumentsList != null) {
              argumentsListStack.push(argumentsList);
            }
            argumentsList = [];
            tokens.shift();
          } else if (argument != null) {
            if (argument != null) {
              if (argument.text == null) {
                argument.text = [];
              }
            }
            argument.text.push('\n' + generateList(tokens));
          }
          break;
        case 'list_item_start':
        case 'loose_item_start':
          if (argument != null) {
            argumentStack.push(argument);
          }
          argument = {};
          tokens.shift();
          break;
        case 'code':
          if (argument.text == null) {
            argument.text = [];
          }
          argument.text.push('\n' + generateCode(tokens));
          break;
        case 'text':
          if (argument.text == null) {
            argument.text = [];
          }
          argument.text.push(token.text);
          tokens.shift();
          break;
        case 'list_item_end':
        case 'loose_item_end':
          if (argument != null) {
            _.extend(argument, parseListItem(argument.text.join(' ').replace(new RegExp(' \n', 'g'), '\n')));
            argumentsList.push(argument);
            delete argument.text;
          }
          argument = argumentStack.pop();
          tokens.shift();
          break;
        case 'list_end':
          depth--;
          if (argument != null) {
            argument.children = argumentsList;
            argumentsList = argumentsListStack.pop();
          } else {
            args = argumentsList;
          }
          tokens.shift();
          break;
        default:
          tokens.shift();
      }
    }
    return args;
  };

  parseListItem = function(argumentString) {
    var description, isOptional, name, nameMatches, type;
    name = null;
    type = null;
    description = argumentString;
    if (nameMatches = new RegExp(ArgumentListItemRegex).exec(argumentString)) {
      name = nameMatches[1];
      description = description.replace(nameMatches[0], '');
      type = getLinkMatch(description);
      isOptional = !!nameMatches[3];
    }
    return {
      name: name,
      description: description,
      type: type,
      isOptional: isOptional
    };
  };

  module.exports = {
    parse: parse
  };

  /*
  Section: Generation
  
  These methods will consume tokens and return a markdown representation of the
  tokens. Yeah, it generates markdown from the lexed markdown tokens.
  */


  isReturnValue = function(string) {
    return new RegExp(ReturnsRegex).test(string);
  };

  isArgumentListItem = function(string) {
    return new RegExp(ArgumentListItemRegex).test(string);
  };

  isAtArgumentList = function(tokens) {
    var foundListStart, token, _i, _len, _ref1;
    foundListStart = false;
    for (_i = 0, _len = tokens.length; _i < _len; _i++) {
      token = tokens[_i];
      if ((_ref1 = token.type) === 'list_item_start' || _ref1 === 'loose_item_start') {
        foundListStart = true;
      } else if (token.type === 'text' && foundListStart) {
        return isArgumentListItem(token.text);
      }
    }
  };

  stopOnSectionBoundaries = function(token, tokens) {
    var listToken, _i, _len, _ref1;
    if ((_ref1 = token.type) === 'paragraph' || _ref1 === 'text') {
      if (isReturnValue(token.text)) {
        return false;
      }
    } else if (token.type === 'heading') {
      if (token.depth === SpecialHeadingDepth && new RegExp(SpecialHeadings).test(token.text)) {
        return false;
      }
    } else if (token.type === 'list_start') {
      listToken = null;
      for (_i = 0, _len = tokens.length; _i < _len; _i++) {
        listToken = tokens[_i];
        if (listToken.type === 'text') {
          break;
        }
      }
      if ((listToken != null) && new RegExp(ArgumentListItemRegex).test(listToken.text)) {
        return false;
      }
    }
  };

  generateDescription = function(tokens, tokenCallback) {
    var description, token, _ref1;
    description = [];
    while (token = _.first(tokens)) {
      if ((tokenCallback != null) && tokenCallback(token, tokens) === false) {
        break;
      }
      if ((_ref1 = token.type) === 'paragraph' || _ref1 === 'text') {
        description.push(generateParagraph(tokens));
      } else if (token.type === 'blockquote_start') {
        description.push(generateBlockquote(tokens));
      } else if (token.type === 'code') {
        description.push(generateCode(tokens));
      } else if (token.type === 'heading') {
        description.push(generateHeading(tokens));
      } else if (token.type === 'list_start') {
        description.push(generateList(tokens));
      } else {
        break;
      }
    }
    return description.join('\n\n');
  };

  generateParagraph = function(tokens) {
    return tokens.shift().text;
  };

  generateHeading = function(tokens) {
    var token;
    token = tokens.shift();
    return "" + (multiplyString('#', token.depth)) + " " + token.text;
  };

  generateBlockquote = function(tokens) {
    var line, lines, token, _i, _len, _ref1;
    lines = [];
    while (token = tokens.shift()) {
      if (token.type === 'blockquote_end') {
        break;
      }
      if (token.text != null) {
        _ref1 = token.text.split('\n');
        for (_i = 0, _len = _ref1.length; _i < _len; _i++) {
          line = _ref1[_i];
          lines.push("> " + line);
        }
      }
    }
    return lines.join('\n');
  };

  generateCode = function(tokens) {
    var lines, token;
    token = tokens.shift();
    lines = [];
    lines.push(token.lang != null ? "```" + token.lang : '```');
    lines.push(token.text);
    lines.push('```');
    return lines.join('\n');
  };

  generateList = function(tokens) {
    var depth, indent, line, linePrefix, lines, ordered, orderedStack, prefix, textLines, token, _i, _len;
    depth = -1;
    lines = [];
    linePrefix = null;
    ordered = null;
    orderedStack = [];
    indent = function() {
      return multiplyString('  ', depth);
    };
    while (token = _.first(tokens)) {
      switch (token.type) {
        case 'list_start':
          depth++;
          orderedStack.push(ordered);
          ordered = token.ordered;
          break;
        case 'list_item_start':
        case 'loose_item_start':
          linePrefix = ordered ? "" + (indent()) + "1. " : "" + (indent()) + "* ";
          break;
        case 'text':
        case 'code':
        case 'blockquote_start':
          if (token.type === 'code') {
            textLines = generateCode(tokens).split('\n');
          } else if (token.type === 'blockquote_start') {
            textLines = generateBlockquote(tokens).split('\n');
          } else {
            textLines = token.text.split('\n');
          }
          for (_i = 0, _len = textLines.length; _i < _len; _i++) {
            line = textLines[_i];
            prefix = linePrefix != null ? linePrefix : "" + (indent()) + "  ";
            lines.push(prefix + line);
            linePrefix = null;
          }
          break;
        case 'list_end':
          depth--;
          ordered = orderedStack.pop();
      }
      token = tokens.shift();
      if (depth < 0) {
        break;
      }
    }
    return lines.join('\n');
  };

}).call(this);
